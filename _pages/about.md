---
layout: about
title: about
permalink: /
subtitle: <a href='#'>Bochum</a>, Germany.

profile:
  align: right
  image: hq.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>Bochum, Germany</p>

news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---

 I'm currently a ~~first~~ second-year PhD student at Ruhr-University Bochum ~~[University of Tuebingen](https://uni-tuebingen.de/en/).~~ I officially moved to [Ruhr-University Bochum](https://www.ruhr-uni-bochum.de/en) in November 2023 with my supervisor [Setareh Maghsudi](https://etit.ruhr-uni-bochum.de/en/lts/team/prof-dr-ing-setareh-maghsudi/). Before coming to Bochum, I spent one wonderful year in [Tuebingen AI center](https://tuebingen.ai/people). I received my Master's degree in Theory and Method of Artificial Intelligence from [Institute of Automation, Chinese Academy of Sciences](http://english.ia.cas.cn/). I also work close with [Prof. Tianyi Zhou](https://tianyizhou.github.io/) at [University of Maryland](https://umd.edu/) and [Prof. Meng Fang](https://mengf1.github.io/) at [University of Liverpool](https://www.liverpool.ac.uk/).


For masters student in RUB: We could provide master's thesis topic, which focuses on (deep) reinforcement learning or deep RL for large language models. Please contact Setareh and me if you are interested in our team.

I am actively looking for research collaborations! For master/undergrad students looking for research experience or PhD students looking for collaborations, feel free to drop me an email.

 <details>
<summary>Research Interests: reinforcement learning, large language models</summary>
<br>

I'm broadly interested in reinforcement learning, large language models, and machine learning. Currently, my research aims to i) understand the structural information of deep RL & LLMs and how to leverage it to improve agent performance in the wild (e.g., dealing with biased, noisy, or redundant data, or extrapolating to unseen tasks/environments), ii) develop controllable AI in both training and inference/adaptation; and iii) theory and real-world application of Human-AI alignment. And Yes we are developing these methods for RL and LLMs.  

Our research is built upon empirical and theoretical analysis of the learning dynamics, utilizing tools from stochastic processes, functional analysis, algebra, optimization, information theory, and large language models. Our goal is to develop efficient, stable, trustworthy agents based on coevolution between humans and agents. 

</details>

<br>
 <details>
<summary>Contact information</summary>


Email: qianghe97 AT gmail DOT com, Qiang DOT He AT ruhr-uni-bochum DOT de. Since I have left Tuebingen, my Tuebingen e-mail is not available. Please contact me via Gmail or Bochum mail. 

WeChat: pposac 

</details>

<br>





<details>
<summary>Professional Service</summary>

Reviewer for 
- NeurIPS
- [DMLR](https://data.mlr.press/)
- [ICPR](https://icpr2024.org/index.html)

</details>