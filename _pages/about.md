---
layout: about
title: about
permalink: /
subtitle: <a href='#'>Bochum</a>, Germany.

profile:
  align: right
  image: qh.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>Bochum, Germany</p>

news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---

 I'm currently a ~~first~~ ~~second~~ third-year PhD student at [Ruhr-University Bochum](https://www.ruhr-uni-bochum.de/en), having moved here in November 2023 with my supervisor [Prof. Dr. Setareh Maghsudi](https://etit.ruhr-uni-bochum.de/en/lts/team/prof-dr-ing-setareh-maghsudi/) from Tuebingen. I earned my Master's degree in Theory and Method of Artificial Intelligence from [Institute of Automation, Chinese Academy of Sciences](http://english.ia.cas.cn/).



I am actively looking for research collaborations! For master/undergrad students looking for research experience or PhD students looking for collaborations, feel free to drop me an email.

 <details>
<summary>Research Interests: Reinforcement Learning, Human-AI Alignment, Large Language Models</summary>
<br>

I'm broadly interested in reinforcement learning, large language models, and machine learning. Currently, my research aims to i) understand the structural information of deep RL & LLMs and how to leverage it to improve agent performance in the wild (e.g., dealing with biased, noisy, or redundant data, or extrapolating to unseen tasks/environments), ii) develop controllable AI in both training and inference/adaptation; and iii) theory and real-world application of Human-AI alignment. And Yes we are developing these methods for RL and LLMs.


<br><br> The working title of my PhD thesis is "Towards Human-friendly Reinforcement Learning: Structural Analysis, Control Mechanisms, and Human-AI Alignment".



<br><br>Our research is built upon the empirical and theoretical analysis of the learning dynamics, utilizing tools from stochastic processes, functional analysis, algebra, optimization, information theory, and large language models. Our goal is to develop efficient, stable, trustworthy agents based on coevolution between humans and agents. 

</details>

<br>
 <details>
<summary>Contact information</summary>


Email: qianghe97 AT gmail DOT com, Qiang DOT He AT ruhr-uni-bochum DOT de.
<br>
WeChat ID: pposac 

</details>

<br>





<details>
<summary>Professional Service</summary>
<br>

Reviewer for ICLR, NeurIPS, DMLR, ICPR

<br>
</details>


<br>
